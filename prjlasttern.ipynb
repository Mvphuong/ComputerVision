{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a208cf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "import cv2\n",
    "import os\n",
    "import glob\n",
    "\n",
    "# =====================================================\n",
    "# 1Ô∏è‚É£ Ki·ªÉm tra dataset v√† t·∫°o b√°o c√°o\n",
    "# =====================================================\n",
    "def check_dataset(dataset_path=\"datasets\"):\n",
    "    \"\"\"Ki·ªÉm tra s·ªë l∆∞·ª£ng images/labels v√† ph√°t hi·ªán file thi·∫øu\"\"\"\n",
    "    print(\"=== Ki·ªÉm tra dataset ===\")\n",
    "    for split in [\"train\", \"val\", \"test\"]:\n",
    "        img_dir = os.path.join(dataset_path, \"images\", split)\n",
    "        lbl_dir = os.path.join(dataset_path, \"labels\", split)\n",
    "        \n",
    "        if not os.path.exists(img_dir):\n",
    "            print(f\"‚ö†Ô∏è  Kh√¥ng t√¨m th·∫•y: {img_dir}\")\n",
    "            continue\n",
    "            \n",
    "        images = set([os.path.splitext(f)[0] for f in os.listdir(img_dir)])\n",
    "        labels = set([os.path.splitext(f)[0] for f in os.listdir(lbl_dir)])\n",
    "        \n",
    "        missing_labels = images - labels\n",
    "        missing_images = labels - images\n",
    "        \n",
    "        print(f\"\\n{split.upper()}:\")\n",
    "        print(f\"  ‚úì {len(images)} images, {len(labels)} labels\")\n",
    "        if missing_labels:\n",
    "            print(f\"  ‚ö†Ô∏è  {len(missing_labels)} ·∫£nh thi·∫øu label\")\n",
    "        if missing_images:\n",
    "            print(f\"  ‚ö†Ô∏è  {len(missing_images)} label th·ª´a (kh√¥ng c√≥ ·∫£nh)\")\n",
    "\n",
    "check_dataset()\n",
    "\n",
    "# =====================================================\n",
    "# 2Ô∏è‚É£ T·∫°o file YAML v·ªõi absolute path\n",
    "# =====================================================\n",
    "yaml_content = f\"\"\"\n",
    "path: {os.path.abspath('datasets')}\n",
    "train: images/train\n",
    "val: images/val\n",
    "test: images/test\n",
    "\n",
    "names:\n",
    "  0: crop\n",
    "  1: weed\n",
    "\"\"\"\n",
    "\n",
    "with open(\"weed.yaml\", \"w\") as f:\n",
    "    f.write(yaml_content)\n",
    "\n",
    "print(\"\\n‚úì File weed.yaml ƒë√£ t·∫°o v·ªõi absolute path!\")\n",
    "\n",
    "# =====================================================\n",
    "# 3Ô∏è‚É£ Hu·∫•n luy·ªán m√¥ h√¨nh (c√≥ th·ªÉ t·∫Øt ƒë·ªÉ test nhanh)\n",
    "# =====================================================\n",
    "TRAIN_MODEL = True  # ƒê·ªïi th√†nh False ƒë·ªÉ skip training\n",
    "\n",
    "if TRAIN_MODEL:\n",
    "    print(\"\\n=== B·∫Øt ƒë·∫ßu hu·∫•n luy·ªán ===\")\n",
    "    model = YOLO(\"yolov8n.pt\")\n",
    "    \n",
    "    model.train(\n",
    "        data=\"weed.yaml\",\n",
    "        epochs=50,\n",
    "        imgsz=640,\n",
    "        batch=8,\n",
    "        device=0,  # 0=GPU, 'cpu'=CPU\n",
    "        project=\"weed_detection\",\n",
    "        name=\"yolov8_weed\",\n",
    "        exist_ok=True,\n",
    "        patience=10,  # Early stopping sau 10 epochs kh√¥ng c·∫£i thi·ªán\n",
    "        save=True,\n",
    "        verbose=True\n",
    "    )\n",
    "    \n",
    "    best_model_path = \"weed_detection/yolov8_weed/weights/best.pt\"\n",
    "else:\n",
    "    # D√πng model ƒë√£ train s·∫µn\n",
    "    best_model_path = \"weed_detection/yolov8_weed/weights/best.pt\"\n",
    "    if not os.path.exists(best_model_path):\n",
    "        print(\"‚ö†Ô∏è  Kh√¥ng t√¨m th·∫•y model ƒë√£ train. D√πng pretrained model.\")\n",
    "        best_model_path = \"yolov8n.pt\"\n",
    "\n",
    "# =====================================================\n",
    "# 4Ô∏è‚É£ ƒê√°nh gi√° m√¥ h√¨nh tr√™n validation v√† test set\n",
    "# =====================================================\n",
    "model = YOLO(best_model_path)\n",
    "\n",
    "print(\"\\n=== ƒê√°nh gi√° tr√™n VALIDATION set ===\")\n",
    "val_metrics = model.val(data=\"weed.yaml\", split=\"val\")\n",
    "print(f\"mAP50: {val_metrics.box.map50:.3f}\")\n",
    "print(f\"mAP50-95: {val_metrics.box.map:.3f}\")\n",
    "\n",
    "print(\"\\n=== ƒê√°nh gi√° tr√™n TEST set ===\")\n",
    "test_metrics = model.val(data=\"weed.yaml\", split=\"test\")\n",
    "print(f\"mAP50: {test_metrics.box.map50:.3f}\")\n",
    "print(f\"mAP50-95: {test_metrics.box.map:.3f}\")\n",
    "\n",
    "# =====================================================\n",
    "# 5Ô∏è‚É£ D·ª± ƒëo√°n tr√™n ·∫£nh test v·ªõi error handling\n",
    "# =====================================================\n",
    "def predict_on_test_images(model, test_dir=\"datasets/images/test\", max_images=5):\n",
    "    \"\"\"D·ª± ƒëo√°n tr√™n t·ªëi ƒëa N ·∫£nh test v√† hi·ªÉn th·ªã k·∫øt qu·∫£\"\"\"\n",
    "    test_images = glob.glob(os.path.join(test_dir, \"*.jpg\"))\n",
    "    \n",
    "    if not test_images:\n",
    "        print(f\"‚ö†Ô∏è  Kh√¥ng t√¨m th·∫•y ·∫£nh test trong {test_dir}\")\n",
    "        return\n",
    "    \n",
    "    print(f\"\\n=== D·ª± ƒëo√°n tr√™n {min(len(test_images), max_images)} ·∫£nh test ===\")\n",
    "    \n",
    "    for img_path in test_images[:max_images]:\n",
    "        print(f\"\\nüì∑ {os.path.basename(img_path)}\")\n",
    "        results = model.predict(img_path, conf=0.5, verbose=False)\n",
    "        \n",
    "        # In th√¥ng tin bbox\n",
    "        for r in results:\n",
    "            if len(r.boxes) == 0:\n",
    "                print(\"  ‚ûú Kh√¥ng ph√°t hi·ªán object\")\n",
    "            else:\n",
    "                for box in r.boxes:\n",
    "                    cls = int(box.cls[0])\n",
    "                    cls_name = \"crop\" if cls == 0 else \"weed\"\n",
    "                    conf = float(box.conf[0])\n",
    "                    x1, y1, x2, y2 = box.xyxy[0].tolist()\n",
    "                    print(f\"  ‚ûú {cls_name.upper()} | Conf: {conf:.2f} | BBox: [{x1:.0f}, {y1:.0f}, {x2:.0f}, {y2:.0f}]\")\n",
    "        \n",
    "        # L∆∞u ·∫£nh c√≥ bbox (kh√¥ng hi·ªÉn th·ªã t·ª± ƒë·ªông)\n",
    "        results[0].save(filename=f\"output_{os.path.basename(img_path)}\")\n",
    "    \n",
    "    print(f\"\\n‚úì ·∫¢nh k·∫øt qu·∫£ ƒë√£ l∆∞u v·ªõi t√™n 'output_*.jpg'\")\n",
    "\n",
    "predict_on_test_images(model, max_images=5)\n",
    "\n",
    "# =====================================================\n",
    "# 6Ô∏è‚É£ Real-time detection t·ª´ webcam (tu·ª≥ ch·ªçn)\n",
    "# =====================================================\n",
    "def webcam_detection(model):\n",
    "    \"\"\"Ph√°t hi·ªán real-time t·ª´ webcam v·ªõi error handling\"\"\"\n",
    "    print(\"\\n=== B·∫Øt ƒë·∫ßu webcam detection (nh·∫•n 'q' ƒë·ªÉ tho√°t) ===\")\n",
    "    \n",
    "    cap = cv2.VideoCapture(0)\n",
    "    \n",
    "    if not cap.isOpened():\n",
    "        print(\"‚ö†Ô∏è  Kh√¥ng th·ªÉ m·ªü webcam. Vui l√≤ng ki·ªÉm tra k·∫øt n·ªëi.\")\n",
    "        return\n",
    "    \n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            print(\"‚ö†Ô∏è  L·ªói ƒë·ªçc frame t·ª´ webcam\")\n",
    "            break\n",
    "        \n",
    "        results = model.predict(frame, conf=0.5, verbose=False)\n",
    "        annotated_frame = results[0].plot()\n",
    "        \n",
    "        cv2.imshow(\"Weed Detection - Real-time\", annotated_frame)\n",
    "        \n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "    \n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "    print(\"‚úì ƒê√£ ƒë√≥ng webcam\")\n",
    "\n",
    "# Uncomment d√≤ng d∆∞·ªõi ƒë·ªÉ ch·∫°y webcam detection\n",
    "# webcam_detection(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "90e22467",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Ki·ªÉm tra dataset ===\n",
      "\n",
      "TRAIN:\n",
      "  ‚úì 1661 images, 1661 labels\n",
      "\n",
      "VALID:\n",
      "  ‚úì 580 images, 580 labels\n",
      "\n",
      "TEST:\n",
      "  ‚úì 245 images, 245 labels\n",
      "\n",
      "‚úì S·ª≠ d·ª•ng data.yaml c√≥ s·∫µn t·ª´ Roboflow: C:\\computervision\\dataset\\data.yaml\n",
      "\n",
      "N·ªôi dung data.yaml:\n",
      "train: ../train/images\n",
      "val: ../valid/images\n",
      "test: ../test/images\n",
      "\n",
      "nc: 1\n",
      "names: ['0 ridderzuring']\n",
      "\n",
      "roboflow:\n",
      "  workspace: roboflow-100\n",
      "  project: grass-weeds\n",
      "  version: 2\n",
      "  license: CC BY 4.0\n",
      "  url: https://universe.roboflow.com/roboflow-100/grass-weeds/dataset/2\n",
      "\n",
      "=== B·∫Øt ƒë·∫ßu hu·∫•n luy·ªán ===\n",
      "Ultralytics 8.3.233  Python-3.10.8 torch-2.7.1+cu118 CUDA:0 (NVIDIA GeForce RTX 3050 Ti Laptop GPU, 4096MiB)\n",
      "\u001b[34m\u001b[1mengine\\trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=8, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, compile=False, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=C:\\computervision\\dataset\\data.yaml, degrees=0.0, deterministic=True, device=0, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=50, erasing=0.4, exist_ok=True, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=640, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.01, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=yolov8n.pt, momentum=0.937, mosaic=1.0, multi_scale=False, name=yolov8_weed, nbs=64, nms=False, opset=None, optimize=False, optimizer=auto, overlap_mask=True, patience=15, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=weed_detection, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=C:\\computervision\\B1\\weed_detection\\yolov8_weed, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=8, workspace=None\n",
      "Overriding model.yaml nc=80 with nc=1\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
      "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
      "  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n",
      "  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
      "  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n",
      "  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
      "  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
      "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
      "  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n",
      "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  1     37248  ultralytics.nn.modules.block.C2f             [192, 64, 1]                  \n",
      " 16                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  1    123648  ultralytics.nn.modules.block.C2f             [192, 128, 1]                 \n",
      " 19                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
      " 22        [15, 18, 21]  1    751507  ultralytics.nn.modules.head.Detect           [1, [64, 128, 256]]           \n",
      "Model summary: 129 layers, 3,011,043 parameters, 3,011,027 gradients, 8.2 GFLOPs\n",
      "\n",
      "Transferred 319/355 items from pretrained weights\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed \n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access  (ping: 0.30.1 ms, read: 4.81.4 MB/s, size: 40.3 KB)\n",
      "\u001b[K\u001b[34m\u001b[1mtrain: \u001b[0mScanning C:\\computervision\\dataset\\train\\labels.cache... 1661 images, 2 backgrounds, 0 corrupt: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 1661/1661  0.0s\n",
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access  (ping: 0.20.1 ms, read: 4.70.9 MB/s, size: 44.3 KB)\n",
      "\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning C:\\computervision\\dataset\\valid\\labels.cache... 580 images, 0 backgrounds, 0 corrupt: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 580/580 454.5Kit/s 0.0s\n",
      "Plotting labels to C:\\computervision\\B1\\weed_detection\\yolov8_weed\\labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.002, momentum=0.9) with parameter groups 57 weight(decay=0.0), 64 weight(decay=0.0005), 63 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 8 dataloader workers\n",
      "Logging results to \u001b[1mC:\\computervision\\B1\\weed_detection\\yolov8_weed\u001b[0m\n",
      "Starting training for 50 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       1/50      1.12G      1.884      2.131      1.583         19        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 208/208 5.4it/s 38.3s<0.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 37/37 6.3it/s 5.9s0.2s\n",
      "                   all        580       1940      0.701      0.664      0.684      0.318\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       2/50      1.28G      1.817      1.599       1.56          6        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 208/208 8.4it/s 24.8s<0.2ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 37/37 10.3it/s 3.6s.2ss\n",
      "                   all        580       1940      0.711      0.655      0.698      0.323\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       3/50      1.29G      1.796       1.43      1.565         13        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 208/208 10.1it/s 20.6s0.2ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 37/37 10.9it/s 3.4s0.2s\n",
      "                   all        580       1940      0.716      0.696      0.718       0.35\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       4/50       1.3G      1.789      1.327       1.56         21        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 208/208 10.3it/s 20.3s0.2ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 37/37 10.9it/s 3.4s0.1s\n",
      "                   all        580       1940      0.717      0.705      0.709      0.333\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       5/50       1.3G      1.779       1.29      1.567         23        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 208/208 10.2it/s 20.5s0.2ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 37/37 10.7it/s 3.4s0.2s\n",
      "                   all        580       1940      0.748      0.671      0.732      0.353\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       6/50       1.3G      1.745      1.256      1.548         19        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 208/208 6.8it/s 30.6s<0.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 37/37 6.2it/s 5.9s0.2s\n",
      "                   all        580       1940      0.753      0.648      0.731      0.353\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       7/50      1.31G      1.732      1.245      1.537          7        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 208/208 6.0it/s 34.9s<0.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 37/37 8.0it/s 4.6s<0.2s\n",
      "                   all        580       1940      0.737      0.694      0.737       0.36\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       8/50      1.32G      1.716      1.245      1.528         17        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 208/208 7.0it/s 29.8s<0.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 37/37 6.4it/s 5.8s0.2s\n",
      "                   all        580       1940      0.745      0.728      0.756      0.375\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       9/50      1.34G        1.7      1.182      1.502         13        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 208/208 6.4it/s 32.4s<0.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 37/37 5.8it/s 6.4s0.2s\n",
      "                   all        580       1940      0.716      0.697      0.731      0.364\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      10/50      1.36G      1.703      1.182      1.502         24        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 208/208 6.5it/s 32.2s<0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 37/37 6.0it/s 6.2s0.2s\n",
      "                   all        580       1940      0.743      0.709      0.746      0.374\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      11/50      1.37G      1.692      1.151       1.49         27        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 208/208 6.2it/s 33.7s0.3ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 37/37 10.8it/s 3.4s0.2s\n",
      "                   all        580       1940       0.76      0.726       0.77      0.385\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      12/50      1.37G      1.683      1.168      1.516         30        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 208/208 10.3it/s 20.3s.2sss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 37/37 11.2it/s 3.3s0.1s\n",
      "                   all        580       1940      0.758      0.721      0.758      0.382\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      13/50      1.37G      1.657      1.141      1.484         13        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 208/208 10.3it/s 20.3s.2sss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 37/37 10.4it/s 3.6s0.2s\n",
      "                   all        580       1940      0.747      0.714      0.761      0.385\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      14/50      1.37G      1.655      1.124      1.504          6        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 208/208 5.7it/s 36.4s<0.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 37/37 5.6it/s 6.7s0.2s\n",
      "                   all        580       1940       0.74      0.729      0.748      0.376\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      15/50      1.37G      1.643      1.099      1.475         21        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 208/208 10.0it/s 20.8s.2sss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 37/37 7.6it/s 4.9s0.2s\n",
      "                   all        580       1940      0.754      0.721      0.762      0.375\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      16/50      1.37G      1.642      1.126      1.488         17        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 208/208 6.0it/s 34.5s<0.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 37/37 6.0it/s 6.2s0.2s\n",
      "                   all        580       1940      0.778      0.702      0.769      0.393\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      17/50      1.37G      1.632      1.098      1.475         16        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 208/208 6.4it/s 32.4s<0.3s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 37/37 4.5it/s 8.2s0.2s\n",
      "                   all        580       1940      0.748      0.736      0.774      0.398\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      18/50      1.37G      1.621      1.093      1.459          9        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 208/208 6.2it/s 33.8s<0.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 37/37 6.2it/s 6.0s0.2s\n",
      "                   all        580       1940      0.748      0.739      0.759       0.38\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      19/50      1.37G      1.632      1.128      1.474         18        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 208/208 6.1it/s 34.3s<0.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 37/37 6.1it/s 6.0s0.2s\n",
      "                   all        580       1940       0.76      0.706      0.768      0.387\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      20/50      1.37G      1.616       1.08      1.464         23        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 208/208 8.4it/s 24.8s0.2sss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 37/37 10.8it/s 3.4s0.2s\n",
      "                   all        580       1940      0.752      0.736      0.763      0.387\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      21/50      1.37G      1.612      1.083      1.464         19        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 208/208 10.0it/s 20.8s.2ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 37/37 10.8it/s 3.4s0.1s\n",
      "                   all        580       1940       0.75      0.736      0.774      0.401\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      22/50      1.37G      1.607      1.075      1.451         13        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 208/208 10.0it/s 20.8s.2sss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 37/37 10.6it/s 3.5s0.2s\n",
      "                   all        580       1940      0.764      0.713      0.768      0.394\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      23/50      1.37G      1.617      1.073       1.46         15        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 208/208 10.1it/s 20.6s.2sss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 37/37 10.7it/s 3.5s0.1s\n",
      "                   all        580       1940      0.754      0.727      0.776      0.404\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      24/50      1.37G      1.592      1.066      1.442         22        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 208/208 9.9it/s 21.0s<0.2ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 37/37 10.8it/s 3.4s0.2s\n",
      "                   all        580       1940      0.741      0.738      0.779      0.398\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      25/50      1.37G      1.606       1.05      1.448         27        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 208/208 10.1it/s 20.6s0.2ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 37/37 10.7it/s 3.5s0.2s\n",
      "                   all        580       1940      0.772      0.741      0.788      0.413\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      26/50      1.37G      1.584      1.072      1.447         14        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 208/208 6.3it/s 33.1s<0.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 37/37 6.2it/s 6.0s0.2s\n",
      "                   all        580       1940      0.752      0.745      0.782      0.409\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      27/50      1.37G      1.574      1.039      1.435         14        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 208/208 5.8it/s 36.0s<0.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 37/37 5.4it/s 6.9s0.2s\n",
      "                   all        580       1940       0.75      0.731      0.776      0.399\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      28/50      1.37G       1.57      1.033      1.427         17        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 208/208 5.7it/s 36.2s<0.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 37/37 5.5it/s 6.8s0.2s\n",
      "                   all        580       1940      0.748      0.731      0.779      0.403\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      29/50      1.37G      1.568      1.054      1.434          7        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 208/208 5.8it/s 36.1s<0.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 37/37 5.4it/s 6.9s0.2s\n",
      "                   all        580       1940      0.756      0.736      0.782      0.405\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      30/50      1.37G      1.562      1.014      1.421         13        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 208/208 6.2it/s 33.4s<0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 37/37 6.3it/s 5.8s0.2s\n",
      "                   all        580       1940      0.758      0.752      0.784        0.4\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      31/50      1.37G      1.561      1.031      1.437         21        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 208/208 6.2it/s 33.8s<0.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 37/37 6.0it/s 6.2s0.2s\n",
      "                   all        580       1940      0.759      0.735      0.778      0.403\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      32/50      1.37G      1.562      1.026      1.427          9        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 208/208 6.4it/s 32.6s<0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 37/37 6.0it/s 6.2s0.2s\n",
      "                   all        580       1940      0.761      0.743      0.788      0.408\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      33/50      1.37G      1.549      1.012      1.433         17        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 208/208 6.2it/s 33.4s<0.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 37/37 6.0it/s 6.1s0.2s\n",
      "                   all        580       1940      0.771      0.715      0.773      0.404\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      34/50      1.37G      1.545       1.02       1.43         13        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 208/208 6.4it/s 32.3s<0.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 37/37 6.1it/s 6.1s0.2s\n",
      "                   all        580       1940      0.756       0.73       0.78      0.407\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      35/50      1.37G      1.548     0.9918      1.415         18        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 208/208 6.5it/s 32.2s<0.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 37/37 6.2it/s 5.9s0.2s\n",
      "                   all        580       1940      0.763      0.741       0.78      0.406\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      36/50      1.37G      1.529     0.9939      1.407         21        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 208/208 6.5it/s 32.1s<0.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 37/37 6.2it/s 5.9s0.2s\n",
      "                   all        580       1940      0.765      0.726       0.78      0.409\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      37/50      1.37G      1.524     0.9859      1.401         11        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 208/208 6.5it/s 32.1s<0.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 37/37 6.2it/s 6.0s0.2s\n",
      "                   all        580       1940      0.756      0.749       0.78      0.409\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      38/50      1.37G      1.509     0.9732      1.391          9        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 208/208 6.8it/s 30.8s<0.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 37/37 6.3it/s 5.9s0.2s\n",
      "                   all        580       1940      0.742      0.752      0.782       0.41\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      39/50      1.37G      1.521     0.9758      1.402         10        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 208/208 6.5it/s 32.0s<0.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 37/37 6.2it/s 6.0s0.2s\n",
      "                   all        580       1940      0.761      0.737      0.776      0.413\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      40/50      1.37G      1.518     0.9841      1.403         15        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 208/208 9.8it/s 21.1s0.2sss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 37/37 11.0it/s 3.4s0.2s\n",
      "                   all        580       1940      0.755      0.735      0.775      0.411\n",
      "\u001b[34m\u001b[1mEarlyStopping: \u001b[0mTraining stopped early as no improvement observed in last 15 epochs. Best results observed at epoch 25, best model saved as best.pt.\n",
      "To update EarlyStopping(patience=15) pass a new patience value, i.e. `patience=300` or use `patience=0` to disable EarlyStopping.\n",
      "\n",
      "40 epochs completed in 0.388 hours.\n",
      "Optimizer stripped from C:\\computervision\\B1\\weed_detection\\yolov8_weed\\weights\\last.pt, 6.2MB\n",
      "Optimizer stripped from C:\\computervision\\B1\\weed_detection\\yolov8_weed\\weights\\best.pt, 6.2MB\n",
      "\n",
      "Validating C:\\computervision\\B1\\weed_detection\\yolov8_weed\\weights\\best.pt...\n",
      "Ultralytics 8.3.233  Python-3.10.8 torch-2.7.1+cu118 CUDA:0 (NVIDIA GeForce RTX 3050 Ti Laptop GPU, 4096MiB)\n",
      "Model summary (fused): 72 layers, 3,005,843 parameters, 0 gradients, 8.1 GFLOPs\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 37/37 9.6it/s 3.8s<0.1s\n",
      "                   all        580       1940      0.772      0.741      0.788      0.413\n",
      "Speed: 0.3ms preprocess, 2.5ms inference, 0.0ms loss, 1.5ms postprocess per image\n",
      "Results saved to \u001b[1mC:\\computervision\\B1\\weed_detection\\yolov8_weed\u001b[0m\n",
      "\n",
      "‚úì Model t·ªët nh·∫•t ƒë√£ l∆∞u t·∫°i: weed_detection/yolov8_weed/weights/best.pt\n",
      "\n",
      "============================================================\n",
      "ƒê√ÅNH GI√Å M√î H√åNH TR√äN VALIDATION SET\n",
      "============================================================\n",
      "Ultralytics 8.3.233  Python-3.10.8 torch-2.7.1+cu118 CUDA:0 (NVIDIA GeForce RTX 3050 Ti Laptop GPU, 4096MiB)\n",
      "Model summary (fused): 72 layers, 3,005,843 parameters, 0 gradients, 8.1 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access  (ping: 0.00.0 ms, read: 689.8151.7 MB/s, size: 43.8 KB)\n",
      "\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning C:\\computervision\\dataset\\valid\\labels.cache... 580 images, 0 backgrounds, 0 corrupt: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 580/580 657.8Kit/s 0.0s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 37/37 6.8it/s 5.5s0.1s\n",
      "                   all        580       1940      0.772      0.741      0.788      0.412\n",
      "Speed: 1.3ms preprocess, 4.7ms inference, 0.0ms loss, 1.3ms postprocess per image\n",
      "Results saved to \u001b[1mC:\\computervision\\B1\\runs\\detect\\val3\u001b[0m\n",
      "\n",
      "üìä K·∫øt qu·∫£ Validation:\n",
      "   mAP50:    0.788\n",
      "   mAP50-95: 0.412\n",
      "   Precision: 0.772\n",
      "   Recall:    0.741\n",
      "\n",
      "============================================================\n",
      "ƒê√ÅNH GI√Å M√î H√åNH TR√äN TEST SET\n",
      "============================================================\n",
      "Ultralytics 8.3.233  Python-3.10.8 torch-2.7.1+cu118 CUDA:0 (NVIDIA GeForce RTX 3050 Ti Laptop GPU, 4096MiB)\n",
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access  (ping: 0.10.0 ms, read: 6.91.5 MB/s, size: 46.8 KB)\n",
      "\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning C:\\computervision\\dataset\\test\\labels.cache... 245 images, 0 backgrounds, 0 corrupt: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 245/245  0.0s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 16/16 5.3it/s 3.0s0.1s\n",
      "                   all        245        664      0.733      0.678      0.719      0.352\n",
      "Speed: 1.7ms preprocess, 5.4ms inference, 0.0ms loss, 1.6ms postprocess per image\n",
      "Results saved to \u001b[1mC:\\computervision\\B1\\runs\\detect\\val4\u001b[0m\n",
      "\n",
      "üìä K·∫øt qu·∫£ Test:\n",
      "   mAP50:    0.719\n",
      "   mAP50-95: 0.352\n",
      "   Precision: 0.733\n",
      "   Recall:    0.678\n",
      "\n",
      "============================================================\n",
      "D·ª∞ ƒêO√ÅN TR√äN 5 ·∫¢NH TEST\n",
      "============================================================\n",
      "\n",
      "[1/5] üì∑ ridderzuring_3109_jpg.rf.70027cf8de61339dc3bd996a3c9114a6.jpg\n",
      "  ‚ûú CROP | Confidence: 80.80% | BBox: [0, 133, 45, 228]\n",
      "  ‚ûú CROP | Confidence: 72.89% | BBox: [280, 54, 361, 127]\n",
      "  ‚ûú CROP | Confidence: 70.03% | BBox: [153, 105, 229, 210]\n",
      "  ‚ûú CROP | Confidence: 65.94% | BBox: [93, 112, 165, 177]\n",
      "  ‚ûú CROP | Confidence: 64.36% | BBox: [251, 236, 303, 290]\n",
      "  ‚ûú CROP | Confidence: 63.39% | BBox: [240, 148, 311, 217]\n",
      "  ‚ûú CROP | Confidence: 62.29% | BBox: [226, 351, 287, 403]\n",
      "  ‚ûú CROP | Confidence: 55.63% | BBox: [170, 252, 226, 326]\n",
      "  ‚ûú CROP | Confidence: 48.50% | BBox: [0, 0, 63, 43]\n",
      "  ‚ûú CROP | Confidence: 45.94% | BBox: [0, 0, 39, 44]\n",
      "  ‚ûú CROP | Confidence: 39.68% | BBox: [90, 98, 230, 209]\n",
      "  ‚ûú CROP | Confidence: 38.02% | BBox: [84, 189, 131, 222]\n",
      "  ‚ûú CROP | Confidence: 30.15% | BBox: [209, 5, 262, 66]\n",
      "  ‚ûú CROP | Confidence: 29.37% | BBox: [147, 208, 201, 264]\n",
      "  ‚ûú CROP | Confidence: 25.72% | BBox: [209, 0, 279, 66]\n",
      "  üìä T·ªïng: 15 crops, 0 weeds\n",
      "\n",
      "[2/5] üì∑ ridderzuring_3123_jpg.rf.f6e9ce7d3f2abc0edf222b07894c8910.jpg\n",
      "  ‚ûú CROP | Confidence: 80.89% | BBox: [314, 171, 384, 250]\n",
      "  ‚ûú CROP | Confidence: 76.79% | BBox: [366, 221, 415, 300]\n",
      "  ‚ûú CROP | Confidence: 74.37% | BBox: [227, 0, 322, 44]\n",
      "  ‚ûú CROP | Confidence: 65.38% | BBox: [210, 157, 255, 228]\n",
      "  ‚ûú CROP | Confidence: 61.41% | BBox: [0, 168, 42, 228]\n",
      "  ‚ûú CROP | Confidence: 48.21% | BBox: [0, 383, 49, 416]\n",
      "  ‚ûú CROP | Confidence: 41.77% | BBox: [388, 45, 416, 82]\n",
      "  ‚ûú CROP | Confidence: 36.03% | BBox: [165, 377, 229, 415]\n",
      "  üìä T·ªïng: 8 crops, 0 weeds\n",
      "\n",
      "[3/5] üì∑ ridderzuring_3126_jpg.rf.66331971411258c03ad216e841a00148.jpg\n",
      "  ‚ûú CROP | Confidence: 82.45% | BBox: [50, 198, 131, 283]\n",
      "  ‚ûú CROP | Confidence: 77.64% | BBox: [119, 341, 181, 406]\n",
      "  ‚ûú CROP | Confidence: 70.95% | BBox: [191, 165, 295, 265]\n",
      "  ‚ûú CROP | Confidence: 68.50% | BBox: [62, 89, 115, 143]\n",
      "  ‚ûú CROP | Confidence: 66.36% | BBox: [172, 113, 226, 169]\n",
      "  ‚ûú CROP | Confidence: 63.00% | BBox: [352, 135, 416, 186]\n",
      "  ‚ûú CROP | Confidence: 53.70% | BBox: [0, 257, 33, 315]\n",
      "  ‚ûú CROP | Confidence: 53.36% | BBox: [327, 202, 397, 318]\n",
      "  ‚ûú CROP | Confidence: 46.99% | BBox: [0, 5, 33, 52]\n",
      "  ‚ûú CROP | Confidence: 34.76% | BBox: [186, 165, 306, 308]\n",
      "  ‚ûú CROP | Confidence: 28.34% | BBox: [237, 220, 313, 311]\n",
      "  üìä T·ªïng: 11 crops, 0 weeds\n",
      "\n",
      "[4/5] üì∑ ridderzuring_3128_jpg.rf.ef0cb8b02d739128b4c1fcd8c0cbf365.jpg\n",
      "  ‚ûú CROP | Confidence: 78.44% | BBox: [268, 286, 349, 369]\n",
      "  ‚ûú CROP | Confidence: 70.32% | BBox: [32, 353, 91, 409]\n",
      "  ‚ûú CROP | Confidence: 65.41% | BBox: [193, 376, 258, 415]\n",
      "  ‚ûú CROP | Confidence: 41.99% | BBox: [40, 0, 139, 27]\n",
      "  üìä T·ªïng: 4 crops, 0 weeds\n",
      "\n",
      "[5/5] üì∑ ridderzuring_3129_jpg.rf.52a0630145ad8f84064d1b17c236d5d3.jpg\n",
      "  ‚ûú CROP | Confidence: 73.39% | BBox: [310, 71, 369, 146]\n",
      "  üìä T·ªïng: 1 crops, 0 weeds\n",
      "\n",
      "‚úì ƒê√£ l∆∞u ·∫£nh k·∫øt qu·∫£ v√†o th∆∞ m·ª•c: predictions/\n",
      "\n",
      "============================================================\n",
      "‚úÖ HO√ÄN TH√ÄNH!\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "from ultralytics import YOLO\n",
    "import cv2\n",
    "import os\n",
    "import glob\n",
    "\n",
    "# =====================================================\n",
    "# C·∫§U H√åNH DATASET\n",
    "# =====================================================\n",
    "DATASET_ROOT = \"C:\\\\computervision\\\\dataset\"  # Th∆∞ m·ª•c ch·ª©a train/, valid/, test/\n",
    "USE_ROBOFLOW_YAML = True  # True = d√πng data.yaml c√≥ s·∫µn, False = t·∫°o m·ªõi\n",
    "\n",
    "# =====================================================\n",
    "# 1Ô∏è‚É£ Ki·ªÉm tra dataset v√† t·∫°o b√°o c√°o\n",
    "# =====================================================\n",
    "def check_dataset(dataset_path=DATASET_ROOT):\n",
    "    \"\"\"Ki·ªÉm tra s·ªë l∆∞·ª£ng images/labels v√† ph√°t hi·ªán file thi·∫øu\"\"\"\n",
    "    print(\"=== Ki·ªÉm tra dataset ===\")\n",
    "    for split in [\"train\", \"valid\", \"test\"]:\n",
    "        img_dir = os.path.join(dataset_path, split, \"images\")\n",
    "        lbl_dir = os.path.join(dataset_path, split, \"labels\")\n",
    "        \n",
    "        if not os.path.exists(img_dir):\n",
    "            print(f\"‚ö†Ô∏è  Kh√¥ng t√¨m th·∫•y: {img_dir}\")\n",
    "            continue\n",
    "            \n",
    "        images = set([os.path.splitext(f)[0] for f in os.listdir(img_dir) if f.endswith(('.jpg', '.png', '.jpeg'))])\n",
    "        labels = set([os.path.splitext(f)[0] for f in os.listdir(lbl_dir) if f.endswith('.txt')])\n",
    "        \n",
    "        missing_labels = images - labels\n",
    "        missing_images = labels - images\n",
    "        \n",
    "        print(f\"\\n{split.upper()}:\")\n",
    "        print(f\"  ‚úì {len(images)} images, {len(labels)} labels\")\n",
    "        if missing_labels:\n",
    "            print(f\"  ‚ö†Ô∏è  {len(missing_labels)} ·∫£nh thi·∫øu label: {list(missing_labels)[:5]}\")\n",
    "        if missing_images:\n",
    "            print(f\"  ‚ö†Ô∏è  {len(missing_images)} label th·ª´a: {list(missing_images)[:5]}\")\n",
    "\n",
    "check_dataset()\n",
    "\n",
    "# =====================================================\n",
    "# 2Ô∏è‚É£ Chu·∫©n b·ªã file YAML\n",
    "# =====================================================\n",
    "if USE_ROBOFLOW_YAML and os.path.exists(os.path.join(DATASET_ROOT, \"data.yaml\")):\n",
    "    yaml_path = os.path.join(DATASET_ROOT, \"data.yaml\")\n",
    "    print(f\"\\n‚úì S·ª≠ d·ª•ng data.yaml c√≥ s·∫µn t·ª´ Roboflow: {yaml_path}\")\n",
    "    \n",
    "    # ƒê·ªçc v√† hi·ªÉn th·ªã n·ªôi dung\n",
    "    with open(yaml_path, \"r\") as f:\n",
    "        print(\"\\nN·ªôi dung data.yaml:\")\n",
    "        print(f.read())\n",
    "else:\n",
    "    # T·∫°o file YAML m·ªõi\n",
    "    yaml_path = \"weed_custom.yaml\"\n",
    "    yaml_content = f\"\"\"path: {os.path.abspath(DATASET_ROOT)}\n",
    "train: train/images\n",
    "val: valid/images\n",
    "test: test/images\n",
    "\n",
    "names:\n",
    "  0: crop\n",
    "  1: weed\n",
    "\"\"\"\n",
    "    \n",
    "    with open(yaml_path, \"w\") as f:\n",
    "        f.write(yaml_content)\n",
    "    \n",
    "    print(f\"\\n‚úì ƒê√£ t·∫°o file YAML m·ªõi: {yaml_path}\")\n",
    "\n",
    "# =====================================================\n",
    "# 3Ô∏è‚É£ Hu·∫•n luy·ªán m√¥ h√¨nh\n",
    "# =====================================================\n",
    "TRAIN_MODEL = True  # ƒê·ªïi th√†nh False ƒë·ªÉ skip training\n",
    "EPOCHS = 50\n",
    "IMG_SIZE = 640\n",
    "BATCH_SIZE = 8\n",
    "\n",
    "if TRAIN_MODEL:\n",
    "    print(\"\\n=== B·∫Øt ƒë·∫ßu hu·∫•n luy·ªán ===\")\n",
    "    model = YOLO(\"yolov8n.pt\")  # yolov8s.pt cho accuracy cao h∆°n\n",
    "    \n",
    "    results = model.train(\n",
    "        data=yaml_path,\n",
    "        epochs=EPOCHS,\n",
    "        imgsz=IMG_SIZE,\n",
    "        batch=BATCH_SIZE,\n",
    "        device=0,  # 0=GPU, 'cpu'=CPU, [0,1]=multi-GPU\n",
    "        project=\"weed_detection\",\n",
    "        name=\"yolov8_weed\",\n",
    "        exist_ok=True,\n",
    "        patience=15,  # Early stopping\n",
    "        save=True,\n",
    "        plots=True,  # L∆∞u confusion matrix, F1 curve...\n",
    "        verbose=True\n",
    "    )\n",
    "    \n",
    "    best_model_path = \"weed_detection/yolov8_weed/weights/best.pt\"\n",
    "    print(f\"\\n‚úì Model t·ªët nh·∫•t ƒë√£ l∆∞u t·∫°i: {best_model_path}\")\n",
    "else:\n",
    "    # D√πng model ƒë√£ train s·∫µn\n",
    "    best_model_path = \"weed_detection/yolov8_weed/weights/best.pt\"\n",
    "    if not os.path.exists(best_model_path):\n",
    "        print(\"‚ö†Ô∏è  Kh√¥ng t√¨m th·∫•y model ƒë√£ train. S·ª≠ d·ª•ng pretrained yolov8n.pt\")\n",
    "        best_model_path = \"yolov8n.pt\"\n",
    "\n",
    "# =====================================================\n",
    "# 4Ô∏è‚É£ ƒê√°nh gi√° m√¥ h√¨nh\n",
    "# =====================================================\n",
    "model = YOLO(best_model_path)\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"ƒê√ÅNH GI√Å M√î H√åNH TR√äN VALIDATION SET\")\n",
    "print(\"=\"*60)\n",
    "val_metrics = model.val(data=yaml_path, split=\"val\")\n",
    "print(f\"\\nüìä K·∫øt qu·∫£ Validation:\")\n",
    "print(f\"   mAP50:    {val_metrics.box.map50:.3f}\")\n",
    "print(f\"   mAP50-95: {val_metrics.box.map:.3f}\")\n",
    "print(f\"   Precision: {val_metrics.box.mp:.3f}\")\n",
    "print(f\"   Recall:    {val_metrics.box.mr:.3f}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"ƒê√ÅNH GI√Å M√î H√åNH TR√äN TEST SET\")\n",
    "print(\"=\"*60)\n",
    "test_metrics = model.val(data=yaml_path, split=\"test\")\n",
    "print(f\"\\nüìä K·∫øt qu·∫£ Test:\")\n",
    "print(f\"   mAP50:    {test_metrics.box.map50:.3f}\")\n",
    "print(f\"   mAP50-95: {test_metrics.box.map:.3f}\")\n",
    "print(f\"   Precision: {test_metrics.box.mp:.3f}\")\n",
    "print(f\"   Recall:    {test_metrics.box.mr:.3f}\")\n",
    "\n",
    "# =====================================================\n",
    "# 5Ô∏è‚É£ D·ª± ƒëo√°n tr√™n ·∫£nh test\n",
    "# =====================================================\n",
    "def predict_on_test_images(model, test_dir=None, max_images=5, conf=0.25):\n",
    "    \"\"\"D·ª± ƒëo√°n tr√™n ·∫£nh test v√† l∆∞u k·∫øt qu·∫£\"\"\"\n",
    "    if test_dir is None:\n",
    "        test_dir = os.path.join(DATASET_ROOT, \"test\", \"images\")\n",
    "    \n",
    "    test_images = glob.glob(os.path.join(test_dir, \"*.jpg\")) + \\\n",
    "                  glob.glob(os.path.join(test_dir, \"*.png\"))\n",
    "    \n",
    "    if not test_images:\n",
    "        print(f\"‚ö†Ô∏è  Kh√¥ng t√¨m th·∫•y ·∫£nh test trong {test_dir}\")\n",
    "        return\n",
    "    \n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"D·ª∞ ƒêO√ÅN TR√äN {min(len(test_images), max_images)} ·∫¢NH TEST\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    # T·∫°o th∆∞ m·ª•c output\n",
    "    output_dir = \"predictions\"\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    \n",
    "    for i, img_path in enumerate(test_images[:max_images], 1):\n",
    "        print(f\"\\n[{i}/{min(len(test_images), max_images)}] üì∑ {os.path.basename(img_path)}\")\n",
    "        results = model.predict(img_path, conf=conf, verbose=False)\n",
    "        \n",
    "        # ƒê·∫øm s·ªë l∆∞·ª£ng t·ª´ng class\n",
    "        crop_count = 0\n",
    "        weed_count = 0\n",
    "        \n",
    "        for r in results:\n",
    "            if len(r.boxes) == 0:\n",
    "                print(\"  ‚ûú Kh√¥ng ph√°t hi·ªán object n√†o\")\n",
    "            else:\n",
    "                for box in r.boxes:\n",
    "                    cls = int(box.cls[0])\n",
    "                    cls_name = \"crop\" if cls == 0 else \"weed\"\n",
    "                    conf_score = float(box.conf[0])\n",
    "                    x1, y1, x2, y2 = box.xyxy[0].tolist()\n",
    "                    \n",
    "                    if cls == 0:\n",
    "                        crop_count += 1\n",
    "                    else:\n",
    "                        weed_count += 1\n",
    "                    \n",
    "                    print(f\"  ‚ûú {cls_name.upper()} | Confidence: {conf_score:.2%} | \"\n",
    "                          f\"BBox: [{int(x1)}, {int(y1)}, {int(x2)}, {int(y2)}]\")\n",
    "        \n",
    "        # T·ªïng k·∫øt\n",
    "        if crop_count > 0 or weed_count > 0:\n",
    "            print(f\"  üìä T·ªïng: {crop_count} crops, {weed_count} weeds\")\n",
    "        \n",
    "        # L∆∞u ·∫£nh c√≥ bbox\n",
    "        output_path = os.path.join(output_dir, f\"pred_{os.path.basename(img_path)}\")\n",
    "        results[0].save(filename=output_path)\n",
    "    \n",
    "    print(f\"\\n‚úì ƒê√£ l∆∞u ·∫£nh k·∫øt qu·∫£ v√†o th∆∞ m·ª•c: {output_dir}/\")\n",
    "\n",
    "predict_on_test_images(model, max_images=5, conf=0.25)\n",
    "\n",
    "\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"‚úÖ HO√ÄN TH√ÄNH!\")\n",
    "print(\"=\"*60)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf_env (3.10.8)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
